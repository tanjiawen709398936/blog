# 算法基础

## 基础知识

### 数据结构

> 数据结构是在计算机中组织数据以便有效使用的一种特殊方式。

常用的数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树

其中最基础的是：数组和链表

#### 数组

> 数组是一块连续的内存空间，可以通过下标准确的查找到元素位置，但是不适合插入和删除元素。

那么通过调用 `splice` 实现插入和删除会怎么样呢？这里分析下 `splice` 的内部实现（顺便提一下`unshift`）

首先要从堆栈开始说，如果你创建了一个数组那么从本质上讲你是在告诉系统需要在内存中开辟多大的堆栈分配空间。当你使用 `push` 时数据会被添加到堆栈的末尾，此时系统发现空间不够大将，然后它分配一个新的空间并将数据复制到新空间，这也就是java的数组为什么一定要指定长度的原因。

然后说 `splice` 和 `unshift`，按照上面的推理：系统如何在数组的前面或者中间开辟一个空间呢？因为数组的内存可以看成一个线性的空间，如果要在数据堆栈已经被占用的情况下在前面添加一个元素，那么必须要将前面的元素位置后移，即从`N`迁移到`N+1`，也就是说使用 `unshift` 和 `splice` 的时候会重新分配内存并复制数据。

下图是 unshift 和 push 的性能曲线，unshift 近似指数型增长

![unshift](../img/algorithm/unshift.png)

#### 链表

> 链表是不连续的代码片段，通过 next 属性连接后一个元素，从而实现链式结构，适合删除和插入元素

* 链表的好处：可以随意穿插元素，只需要替换next的内容就可以了。
  * 链表读取的运行时间是 O(n)
  * 链表插入的运行时间是 O(1)
* 数组的好处：数组知道每一个元素的地址，而链表需要从头开始遍历。
  * 数组读取的运行时间是 O(1)
  * 数组插入的运行时间是 O(n)

主要的链表结构：

1. 单链表：尾节点的 next 为空
2. 循环链表：尾节点的 next 指向首节点
3. 双链表：节点不仅有 next 还有 prev 指向上一个节点（当然内存占用大）

王争老师的几个链表练习推荐（LeetCode对应编号：206，141，21，19，876。）

* 单链表反转
* 链表中环的检测
* 两个有序的链表合并
* 删除链表倒数第 n 个结点
* 求链表的中间结点

### 大O表示法

什么是大O表示法？

大O表示法表示的是**忽略系数和常量后最糟糕的运行时间**，比如：普通遍历100个元素的数组，最少1次就找到元素，最多查找100次。这样去最糟糕运行时间，也就是时间复杂度为`O(n)`


为什么需要大O表示法？

算法的速度并非时间，而是操作数的增速。大O表示法可以更加直观的方式表示算法的计算效率。

比如：如果查询100个元素的list，普通遍历需要100次，二分法需要7次。看起来二分法的查找效率是普通遍历的15倍。而如果查询1亿个元素的list，二分法需要32次，通过上面得出的结论，普通遍历只需要 32*15 次，但是实际上是1亿次。用大O表示法，普通遍历是O(n)而二分法是O(log n)

常见的大O表示法运行时间

* `O(log n)`：对数时间，比如：二分法
* `O(n)`：线性时间，比如：简单遍历
* `O(n * log n)`：比如：快排
* `O(n^2)`：比如：选择排序
* `O(n!)`：n的阶乘，比如：旅行商问题


大O表示法的log计算时比较复杂的。这里单独列出来，《算法图解》里面是这么介绍的：

![log](../img/algorithm/log.png)

实际场景中：当我们遇到下面算法时应该怎么计算？

 ```js
 i=1;
 while (i <= n)  {
   i = i * 2;
   //  或者 i = i * 3; i = i * 10;
 }
 ```

要比较 i 和 n 的大小，而 i 每次都乘 2，得到 i 每次计算的值分别为 2、2<sup>2</sup>、2<sup>3</sup>、...、2<sup>x</sup>

最后得到 ：2<sup>x</sup> = n; 则 复杂度为 log<sub>2</sub>n

由于大O表示法会忽略系数和常量，所以最后得到复杂度为 `log n`


## 五大算法

> 递归、分治、动态规划、贪心算法 是必须要掌握的

### 一、分治算法 （Divide And Conquer，简称：DC）

> 将规模为 N 的问题分解为 K 个规模较小的子问题，这些**子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解**

分治算法一般都会用递归实现。步骤为：

1. 递：大问题分解为小问题
2. 解决：如果问题足够小则直接求解
3. 归：将小问题的结果合并

由于递归算法都有 `递` 和 `归` 的过程，自然递归算法只能通过自顶向下实现。

#### 案例1：归并排序

ps：归并排序就是一种排序算法，其时间复杂度为 O(n*logn)，仅次于快速排序

实现思路：将需要排序的数组分解成多个已排序的子项，然后合并并排序子项。

```js
  // 归并排序 -> 利用分治递归思想
  let arr = [9, 7, 3, 7, 1, 3, 5, 2];
  
  // 拆分
  function mergeSort(item) {
    const len = item.length;
    if (len === 1) {
      return item;
    }
    const mid = Math.floor(len / 2);
    const left =  item.slice(0, mid);
    const right = item.slice(mid);
    return merge(mergeSort(left), mergeSort(right));
  }
  
  // 合并子项
  // 该合并有很大缺陷，因为使用了shift
  // function merge(left, right) {
  // 	const leftLen = left.length;
  // 	const rightLen = right.length;
  // 	let result = [];
  // 	while(left.length > 0 && right.length > 0) {
  // 		if (left[0] < right[0]) {
  // 			result.push(left.shift())
  // 		} else {
  // 			result.push(right.shift())
  // 		}
  // 	}
  // 	return result.concat(left).concat(right)
  // }
  
  // 合并子项
  function merge(left, right) {
    const result = [];
    let il = 0;
    let ir = 0;
  
    // left, right本身肯定都是从小到大排好序的
    while(il < left.length && ir < right.length) {
      if (left[il] < right[ir]) {
        result.push(left[il]);
        il++;
      } else {
        result.push(right[ir]);
        ir++;
      }
      
    }
  
    // 当有一方遍历结束后，将有剩余放push到已排序数组
    // 左边
    while (il < left.length) { 
      result.push(left[il]);
      il++;
    }
    // 右边
    while(ir < right.length) {
      result.push(right[ir]);
      ir++;
    }
    
    return result;
  }
  
  const result = mergeSort(arr)
  console.log(arr, 'arr')
  console.log(result, 'result')
```

#### 案例2: 斐波拉契数列

斐波拉契数列：数列从第3项开始,每一项都等于前两项之和，即： 1 + 2 + 3 + 5 + 8 ...

简单版的分治实现方式：

```js
function fibonacci(n) {
  if (0 == n || 1 == n) {
    return n;
  }
  return fibonacci(n - 1) + fibonacci(n - 2);
```

这递归看起来很棒，但是时间复杂度为 `O(2^n)`，而暴力求解的时间复杂度为 `O(n)`，下面是暴力求解的实现：

```js
// 暴力求解斐波拉契数列
function fibonacci(n) {
  const resolution = [0, 1, 3]
  if(n < 3) { return resolution[n]; }

  let i = 1;
  let fib1 = 1, fib2 = 2, fib = 0;
  while(i < n) {
    fib = fib1 + fib2;
    fib1 = fib2;
    fib2 = fib;
    i++;
  }
  return fib; // 输出答案
}
```

为何上述递归分治会很低效？以 `fibonacci(10)` 为例，它经过了以下计算：

1. fibonacci(10) = fibonacci(9) + fibonacci(8)
2. fibonacci(9) = fibonacci(8) + fibonacci(7)
3. 8、7、6、5...
4. fibonacci(4) = fibonacci(3) + fibonacci(2)
5. fibonacci(3) = fibonacci(2) + fibonacci(1)

通过穷举可以发现：每次递归时都有子问题已经进行过计算，而后续的处理中我们依然对其重复处理。这就是著名的 **重叠子问题**

##### 如何解决重叠子问题

解决重叠子问题的法宝就是：备忘录

例如处理斐波拉契数列的时候：我们可以把已经计算好的子问题的答案记录到备忘录里，在后续求解时先从备忘录中取值，如果发现是重叠问题就把答案取出来复用，这样就能减少递归的消耗。

优化版斐波拉契递归：

```js
function fibonacci(n, memo) {
  if (0 == n || 1 == n) { return n; }
  if (memo[n] !== undefined) { return memo[n]; } // 看来备忘录中找到了之前计算的结果，既然找到了，直接返回，避免重复计算

  memo[n] = fibonacci(n - 1, memo) + fibonacci(n - 2, memo);
  return memo[n];
}

function fibonacciAdvance(n) {
  let memo = new Array(n + 1);
  return fibonacci(n, memo);
}
```

上面的代码通过数组来做备忘录时间复杂度为 `O(n)`，但是遇到 n 特别大的情况呢？那时数组会占用很大的连续内存，则可能出现卡顿。如果处理这类场景呢？

此时可以采用 Map 做备忘录。但是Map的检索性能肯定是不如数组的。你可能会有疑问：what？Map的检索不是O(1)吗？为什么Map会比数组要慢？

因为Map通常都会使用经过设计的数据结构来避免hash冲突，因此实际的速度肯定不如直接访问数组的特定位置。（会在下文具体说明）


### 二、贪心算法

> 在对问题求解时，**总是做出在当前看来是最好的选择**。也就是说，不从整体最优考虑，算法得到的是局部最优解

故：使用贪心算法时前面的选择不能影响后续的选择

#### 案例1

[买卖股票的最佳时机 II](https://leetcode-cn.com/leetbook/read/top-interview-questions-easy/x2zsx1/)

给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。

注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。

示例 1:

```
输入: [7,1,5,3,6,4]

输出: 7

解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。
     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。
```

解题思路：[参考](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/solution/tan-xin-suan-fa-by-liweiwei1419-2/)

从第 i 天（这里 i >= 1）开始，与第 i - 1 的股价进行比较，如果股价有上升（严格上升），就将升高的股价（ prices[i] - prices[i- 1] ）记入总利润，按照这种算法，得到的结果就是符合题意的最大利润。


```js
// 也就是说只要能赚钱就进行一次买卖。
let res =  (prices[3] - prices[2]) + (prices[2] - prices[1]) + (prices[1] - prices[0])

// 等价于
let res =  prices[3] - prices[0]
```

#### 案例2:

假设我们有 1 元、2 元、5 元、10 元、20 元、50 元、100 元这些面额的纸币，它们的张数分别是 c1、c2、c5、c10、c20、c50、c100。我们现在要用这些钱来支付 K 元，最少要用多少张纸币呢？

解题思路：找到当前节点的最优解，即用面值最大的进行支付。如果不够，就继续用第二大的进行支付。

不过会有这样的问题：如果需要支付6元，但是剩余的纸币张数分别是 5元2张、2元3张、1元0张，这时使用贪心算法会优先使用5元，因为没有1元的纸币，所以结果为不能支付。

针对上面的问题需要在贪心算法中加入回溯算法，即在使用5月纸币不能支付时采用2元纸币进行尝试。这样就能获得一个新的答案：使用3次2元纸币进行支付。

通过上述问题可以发现贪心算法的局限性：

1. 不能保证求得的最后解是最佳的；
2. 不能用来求最大或最小解问题；
3. 只能求满足某些约束条件的可行解的范围。

我们往往需要使用回溯来优化贪心算法，否则就会导致算法失效。因此，在求解最值问题时，我们需要更好的方法来解，考虑整体最优的问题，也就是下面的动态规划。



### 三、动态规划算法（Dynamic Programming，简称：DP）

> 类似于分治算法，将待求解问题分解成若干个子问题，先求解子问题，然后从子问题的解得到原问题的解。与分治法不同的是，**经分解得到子问题往往不是互相独立的**

举例：斐波那契数列 0,1,1,2,3,5,8,13,…

它的每个数字都与前两个紧邻的数字相关。如果 F(n) 是第 n 个数字，那么我们会有 `F(n) = F(n-1) + F(n-2)`。这个在数学上称作*递归方程*或者*递推关系*。为了计算后面的项，它需要前面项的计算结果作为输入

动态规划问题一定具备以下三个特征：

1. 重叠子问题：在穷举的过程中（比如通过递归），存在重复计算的现象；
2. 无后效性：子问题之间的依赖是单向性的，某阶段状态一旦确定，就不受后续决策的影响；
3. 最优子结构：子问题之间必须相互独立，或者说后续的计算可以通过前面的状态推导出来。



### 四、回溯算法

> 回溯法是一种搜索算法，类似枚举的搜索尝试过程。复杂的，规模较大的问题都可以使用回溯法

回溯：也就是进行一次次的尝试（穷举）

案例：

1. 数独
2. 八皇后：`leetcode 51 和 52 题`
3. 0-1 背包
4. 图的着色
5. 旅行商问题
6. 全排列


### 五、分支限界法

> 回溯算法是深度优先，那么分支限界法就是广度优先的一个经典的例子。回溯法一般来说是遍历整个解空间，获取问题的所有解，而分支限界法则是获取一个解

了解了解就好了...



## 算法技巧

### 双指针

> 双指针在处理链表的时候特别有用

#### 案例1：判断单链表是否成环（快慢指针）

如果单链表成环，那么必定出现慢指针和快指针重合的情况

案例2: [删除排序数组中的重复项](https://leetcode-cn.com/leetbook/read/top-interview-questions-easy/x2gy9m/)

#### 案例2: 不实用indexof实现字符串includes

通过双指针确定需要从字符串中获取的内容长度（star指针和end指针），通过slice获取样本（如果不能使用slice方法可以通队列实现一个），然后用样本和校验值做比较，如果不匹配就star和end递增。


### 散列思想

就是用map储存数据，从而形成一个hash表，然后用hash表储存数据

##### 案例1：[两数之和](https://leetcode-cn.com/problems/two-sum/)


## 复杂数据结构

### 栈

> 栈是一种：后进先出结构

由于栈的输出顺序和输入顺序相反，所以栈通常用于对 "历史" 的回溯。

常用的栈结构有：浏览器的前进后退，V8的上下文调用栈

栈是基于数组/链表实现的：

1. 用数组实现栈：（顺序栈）：用自带的 push 和 pop 可以解决，但是需要处理扩容的问题。
1. 用链表实现栈：（链式栈）：用头节点做栈顶，然后处理头节点就可以了

案例：`leetcode 20 题`：判断括号字符串是否有效

### 队列

> 队列是一种：先进先出结构

由于队列的输出顺序和输入顺序相同，所以队列通常用于对 "历史" 的回放。

JavaScript中事件队列就是一个典型的应用。

队列的实现也是基于数组和链表实现的：

1. 用数组实现：主要是需要解决 shift 的内存重排的问题，可以通过循环数组来解决。也需要解决扩容的问题
2. 用链表实现：push 到尾部，pop 头部

案例：

1. `leetcode 239 题`：滑动窗口的最大值
2. `leetcode 232题`：使用栈实现队列
3. `leetcode 225题`：使用队列实现栈

### 优先队列

> 最高优先级先出的原则

实现方式：

1. 利用堆实现（斐波拉契堆、严格斐波拉契堆）
2. 利用二叉查找树实现

案例：`leetcode 703 题`：返回数据流中的第 k 大的元素。（Java中自带PriorityQueue）


### 散列表（hash表、哈希表）

> 插入删除查找都是O(1), 是最常用的，但其缺点是不能顺序遍历以及扩容缩容的性能损耗。

散列表是基于数组实现的，通过散列函数来寻找映射，根据 key-value 来访问。

当插入的数据越来越多时，可能会出现`hash冲突（散列冲突）`，解决的方法一般有 2 种：

1. 开放寻址法

开放寻址的意思就是如果如果第一次没空位就换个方式找，比如每次后移一位直到找到空位为止。

2. 链表法（java 的 HashMap 采用了这种方法）

链表法就是数组中的元素存放的是一个链表，如果有散列冲突就放在该节点的 next 位置。

散列表的缺点：

1. 散列表是基于数组的，所以会出现扩容问题，当散列表数据更新频繁的时候会出现性能问题
2. 使用了散列函数，会导致很难进行顺序遍历

案例：

1. `leetcode 1 题`：两数之和
2. `leetcode 242 题`：有效字母异位词

### 跳表

> 插入删除查找都是O(logn), 并且能顺序遍历。缺点是空间复杂度O(n)。

跳表是在链表的基础上添加多级索引（类似于二分法）

适用于不那么在意内存空间的，其顺序遍历和区间查找非常方便。Redis 中的有序集合（Sorted Set）就是用跳表来实现的。

### 二叉树

> 树是一种非线性数据结构

树可以看成是链表的变体，在链表中添加了left/right等属性从而产生了树状结构，其中二叉查找/搜索树满足：所有节点的左节点小于当前节点且右节点大于当前节点

从节点之间位置关系的角度来看，二叉树的遍历分为 4 种。

1. 前序遍历（DFS）
   1. 遍历顺序：根节点、左子树、右子树。（根在前面遍历）
2. 中序遍历（DFS）
   1. 遍历顺序：左子树、根节点、右子树。（根在中间遍历）
   2. 如果是二叉查找树中序遍历的结果将是有序数组
3. 后序遍历（DFS）
   1. 遍历顺序：左子树、右子树、根节点。（根在后面遍历）
4. 层序遍历（BFS）

ps：
* DFS = Depth First Search
* BFS = Breadth First Search

案例：

1. `leetcode 98 题`：验证二叉查找树
2. `leetcode 235 题`：寻找二叉树最近公共祖先
3. `leetcode 236 题`：寻找二叉查找树最近公共祖先
4. `leetcode 102 题`：二叉树的层次遍历
5. `leetcode 104 题`：二叉树的最大深度
6. `leetcode 111 题`：二叉树的最小深度

### 红黑树

> 插入删除查找都是O(logn), 中序遍历即是顺序遍历，稳定。缺点是难以实现，去查找不方便。

红黑树是一个`近似平衡二叉树`

红黑树相对跳表实现更为复杂，但红黑树历史更久并已经在多处使用。

### 字典树（Trie 树）

> 适合查找前缀匹配的字符串，很消耗内存

应用场景：比如谷歌搜索时关键字提示

就是把字符串分割，按顺序放入树中：比如 here 和 hero 的前面都是 h（第一层）、e（第二层）

案例：

1. `leetcode 208 题`：实现一个 Trie 树

### 图

> 图用来形容关系

图也可以看成是链表的变体，链表中添加了previous之类的指针从而产生了图状结构

应用场景：朋友圈、微博等好友关系

常用的图

1. 邻接矩阵（也就是二维数组），空间占用大
2. 邻接表（一维数组 + 链表）
